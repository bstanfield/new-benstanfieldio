{
  "title": "Opioids, Self-delusion, and AI",
  "slug": "thoughts-on-empire-of-pain",
  "date": "2026-01-05",
  "content": "I recently finished reading Empire of Pain by Patrick Radden Keefe, which chronicles the Sackler family—the dynasty behind America’s opioid crisis.\n\nKeefe accomplishes a herculean task: tracing three generations of Sacklers, from Arthur Sackler, who pioneered modern medical marketing and helped build Purdue Pharma, through his brothers and their many descendants. The book is sprawling, meticulous, and unsettling.\n\nIts themes are familiar—greed, corruption, power—but what struck me most was something subtler: self-deception. None of the central figures ever admit wrongdoing or meaningful culpability for Purdue’s role in the crisis. This may partly reflect legal caution or personal pride, but it reads as something deeper. Many of the Sacklers, and their close associates, appear to have fully deceived themselves—willfully ignoring facts that implicated them directly.\n\nIt’s as if, once a person crosses a threshold where their identity, career, and legacy are bound to a belief, that belief becomes nearly impossible to dislodge—even when the evidence is overwhelming. To abandon it would mean unraveling the story they tell about who they are.\n\nThat idea lingered with me. If self-deception often emerges when belief, identity, and livelihood become tightly coupled, then it’s worth asking where that coupling might exist in my life.\n\nI work in and around artificial intelligence systems whose impacts are rapidly expanding. The sheer power and possibility of AI can be intoxicating. But what about the potential of massive job loss precipitated by competent general AI systems, or the near-impossible task of crediting writers, artists, musicians, engineers, and so-on for their work that is used to train AI models?\n\nAs AI becomes more capable and embedded in everyday decision-making, the temptation to defend outcomes—especially ones tied to our own work—will only grow. The challenge, I think, is to not be caught in a bubble of like-minded dialogue. Open discussion about the benefits and downsides of AI, as well as a healthy reading of historical precedent, is crucial.\n\nIf I have a hope for my own future working with AI, it’s a modest one: to stay alert to when confidence turns into reflex, when critique feels threatening rather than useful, and when success makes it harder—not easier—to change course. That kind of vigilance may not prevent every mistake, but it might help avoid the far more dangerous one: convincing myself that I’m incapable of making them at all.",
  "published": false,
  "coverImage": null
}