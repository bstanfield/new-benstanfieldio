{
  "title": "Opioids, Self-delusion, and AI",
  "slug": "thoughts-on-empire-of-pain",
  "date": "2026-01-05",
  "content": "I recently finished [*Empire of Pain*](https://www.goodreads.com/book/show/43868109-empire-of-pain) by Patrick Radden Keefe, which chronicles the Sackler family—the dynasty behind America’s opioid crisis.\n\nKeefe accomplishes a herculean task: tracing three generations of Sacklers, from Arthur Sackler, who pioneered modern medical marketing and helped build Purdue Pharma, through his brothers and their many descendants. The book is sprawling, meticulous, and unsettling.\n\nIts themes are familiar—greed, corruption, power—but what struck me most was something subtler: self-deception. None of the central figures ever admit wrongdoing or meaningful culpability for Purdue’s role in the crisis. This may partly reflect legal caution or personal pride, but it reads as something deeper. Many of the Sacklers, and their close associates, appear to have fully deceived themselves—willfully ignoring facts that implicated them directly.\n\nIt’s as if, once a person crosses a threshold where their identity, career, and legacy are bound to a belief, that belief becomes nearly impossible to dislodge—even when the evidence is overwhelming. To abandon it would mean unraveling the story they tell about who they are.\n\nIf self-deception emerges when belief, identity, and livelihood become tightly coupled, then it’s worth asking whether a similar coupling might exist in my life. \n\nI work in and around artificial intelligence systems whose impacts are rapidly expanding. The sheer power and possibility of AI can be intoxicating. But what about the potential of massive job loss precipitated by competent general AI systems, or the near-impossible task of crediting writers, artists, musicians, engineers, and so-on for their work that is used to train AI models?\n\nAs AI becomes more capable and embedded in everyday decision-making, the temptation to defend outcomes—especially ones tied to our own work—will only grow. The challenge, I think, is to not be caught in a bubble of like-minded dialogue. Open discussion about the benefits and downsides of AI, as well as a healthy reading of historical precedent, is crucial.\n\nI don’t have a clean conclusion here. The Sacklers’ story is an extreme one, but it lingers as a reminder of how belief can harden once success and identity become intertwined.\n\nIn AI, clear winners are already beginning to emerge—companies, models, and approaches that appear to be “working,” at least by today’s metrics. With that success comes influence, insulation, and a growing incentive to defend existing choices rather than revisit them. History suggests that this is the moment when reflection becomes hardest, and therefore most necessary.\n\nWhether AI follows a more constructive path remains a developing story. The technology will keep changing, but the more important variable may be whether those shaping it retain the ability to question their own certainty—even, and especially, when the incentives to do otherwise are strongest.",
  "published": false,
  "coverImage": null
}